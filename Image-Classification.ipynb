{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from imageio.v2 import imread\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "train_labels = []\n",
    "\n",
    "test_labels = []\n",
    "    \n",
    "train_images = []\n",
    "test_images = []\n",
    "\n",
    "count = 0\n",
    "for file_name in os.listdir('/kaggle/input/130k-universal-images-apparel/apparel_ppm'):\n",
    "    if file_name.endswith('.ppm'):\n",
    "        image = imread('/kaggle/input/130k-universal-images-apparel/apparel_ppm/' + file_name)\n",
    "        if count < 100:\n",
    "            train_images.append(image)\n",
    "            train_labels.append(0)\n",
    "        elif count < 125:\n",
    "            test_images.append(image)\n",
    "            test_labels.append(0)\n",
    "        else:\n",
    "            break\n",
    "        count += 1\n",
    "               \n",
    "count = 0\n",
    "for file_name in os.listdir('/kaggle/input/130k-universal-images-artwork/artwork_ppm'):\n",
    "    if file_name.endswith('.ppm'):\n",
    "        image = imread('/kaggle/input/130k-universal-images-artwork/artwork_ppm/' + file_name)\n",
    "        if count < 100:\n",
    "            train_images.append(image)\n",
    "            train_labels.append(1)\n",
    "        elif count < 125:\n",
    "            test_images.append(image)\n",
    "            test_labels.append(1)\n",
    "        else:\n",
    "            break\n",
    "        count += 1\n",
    "        \n",
    "count = 0\n",
    "for file_name in os.listdir('/kaggle/input/130k-universal-images-cars/cars_ppm'):\n",
    "    if file_name.endswith('.ppm'):\n",
    "        image = imread('/kaggle/input/130k-universal-images-cars/cars_ppm/' + file_name)\n",
    "        if count < 100:\n",
    "            train_images.append(image)\n",
    "            train_labels.append(2)\n",
    "        elif count < 125:\n",
    "            test_images.append(image)\n",
    "            test_labels.append(2)\n",
    "        else:\n",
    "            break\n",
    "        count += 1\n",
    "\n",
    "count = 0\n",
    "for file_name in os.listdir('/kaggle/input/130k-universal-images-dishes/dishes_ppm'):\n",
    "    if file_name.endswith('.ppm'):\n",
    "        image = imread('/kaggle/input/130k-universal-images-dishes/dishes_ppm/' + file_name)\n",
    "        if count < 100:\n",
    "            train_images.append(image)\n",
    "            train_labels.append(3)\n",
    "        elif count < 125:\n",
    "            test_images.append(image)\n",
    "            test_labels.append(3)\n",
    "        else:\n",
    "            break\n",
    "        count += 1\n",
    "        \n",
    "count = 0\n",
    "for file_name in os.listdir('/kaggle/input/130k-universal-images-furniture/furniture_ppm'):\n",
    "    if file_name.endswith('.ppm'):\n",
    "        image = imread('/kaggle/input/130k-universal-images-furniture/furniture_ppm/' + file_name)\n",
    "        if count < 100:\n",
    "            train_images.append(image)\n",
    "            train_labels.append(4)\n",
    "        elif count < 125:\n",
    "            test_images.append(image)\n",
    "            test_labels.append(4)\n",
    "        else:\n",
    "            break\n",
    "        count += 1\n",
    "        \n",
    "count = 0\n",
    "for file_name in os.listdir('/kaggle/input/130k-universal-images-storefronts/storefronts_ppm'):\n",
    "    if file_name.endswith('.ppm'):\n",
    "        image = imread('/kaggle/input/130k-universal-images-storefronts/storefronts_ppm/' + file_name)\n",
    "        if count < 100:\n",
    "            train_images.append(image)\n",
    "            train_labels.append(5)\n",
    "        elif count < 125:\n",
    "            test_images.append(image)\n",
    "            test_labels.append(5)\n",
    "        else:\n",
    "            break\n",
    "        count += 1\n",
    "        \n",
    "\n",
    "import numpy as np\n",
    "train_labels = np.array(train_labels)\n",
    "train_images = np.array(train_images)\n",
    "test_labels = np.array(test_labels)\n",
    "test_images = np.array(test_images)\n",
    "\n",
    "# normalization that takes too long\n",
    "# for i in range(len(train_images)):\n",
    "#     for x in range(512):\n",
    "#         for y in range(512):\n",
    "#             for c in range(3):\n",
    "#                 train_images[i][x][y][c] = train_images[i][x][y][c] / 255.0\n",
    "\n",
    "# for i in range(len(test_images)):\n",
    "#     for x in range(512):\n",
    "#         for y in range(512):\n",
    "#             for c in range(3):\n",
    "#                 test_images[i][x][y][c] = test_images[i][x][y][c] / 255.0\n",
    "\n",
    "labels = ['clothes', 'art', 'cars', 'dishes', 'furniture', 'storefronts']#, 'drawings', 'landmarks', 'memes', 'groceries', 'storefronts', 'toys']\n",
    "\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu', input_shape=(512, 512, 3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(6))\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "results = model.fit(train_images, train_labels, batch_size=64, epochs=4, \n",
    "                    validation_data=(test_images, test_labels))\n",
    "\n",
    "plt.plot(results.history['accuracy'], label='accuracy')\n",
    "plt.plot(results.history['val_accuracy'], label = 'test_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0, 1])\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U sentence-transformers\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "trans_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "import sys\n",
    "sys.path.append('../input/sentence-transformers-222/sentence-transformers')\n",
    "from sentence_transformers import models\n",
    "trans_model = SentenceTransformer('/kaggle/input/sentence-transformers-222/all-MiniLM-L6-v2')\n",
    "\n",
    "sub_images = []\n",
    "for file_name in os.listdir('/kaggle/input/stable-diffusion-image-to-prompts/images/'):\n",
    "    image = imread('/kaggle/input/stable-diffusion-image-to-prompts/images/' + file_name)\n",
    "    sub_images.append(image)\n",
    "        \n",
    "predict_output = model.predict(np.array(sub_images))\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "j = 0\n",
    "for i in range(20):\n",
    "    plt.subplot(5, 5, i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(test_images[j])\n",
    "    plt.xlabel(labels[test_labels[j]])\n",
    "    j += 1\n",
    "plt.show\n",
    "\n",
    "sentences = []\n",
    "numbers = []\n",
    "for i in range(len(predict_output)):\n",
    "    maximum = 0\n",
    "    for j in range(len(predict_output[i])):\n",
    "        if predict_output[i][j] > maximum:\n",
    "            maximum = predict_output[i][j]\n",
    "            index = j\n",
    "        print(round(predict_output[i][j]))\n",
    "    sentences.append(labels[index])\n",
    "    print(sentences[i])\n",
    "                     \n",
    "    numbers.append(trans_model.encode(sentences[i]).flatten())\n",
    "    #print(numbers)\n",
    "#print(numbers[0])\n",
    "\n",
    "import pandas as pd\n",
    "prompts = pd.read_csv('/kaggle/input/promptssss1/promptss1.csv', index_col='imgId')\n",
    "print(prompts.head(10))\n",
    "prompt_embeddings = trans_model.encode(prompts['prompt']).flatten()\n",
    "print(len(prompt_embeddings))\n",
    "print(prompt_embeddings)\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "comp_path = Path('/kaggle/input/stable-diffusion-image-to-prompts/')\n",
    "sample_submission = pd.read_csv(comp_path / 'sample_submission.csv', index_col='imgId_eId')\n",
    "print(sample_submission.tail())\n",
    "    \n",
    "\n",
    "df = pd.DataFrame(columns=['imgId_eId', 'val'])\n",
    "\n",
    "image_id = ['20057f34d', '227ef0887', '92e911621', 'a4e1c55a9', 'c98f79f71', 'd8edf2e40', 'f27825b2c']\n",
    "for i in range(7):\n",
    "    for j in range(384):\n",
    "        df.loc[(i-1)*384+j, 'imgId_eId'] = image_id[i] + '_' + str(j)\n",
    "        df.loc[(i-1)*384+j, 'val'] = prompt_embeddings[i][j]\n",
    "\n",
    "pd.DataFrame(df).to_csv('/kaggle/working/submission.csv')\n",
    "\n",
    "df.append({'imgId_eId': 'dishes'}, ignore_index=True)\n",
    "print(df)\n",
    "        \n",
    "import numpy as np\n",
    "#assert np.all(np.isclose(sample_submission['val'].values, prompt_embeddings, atol=1e-07))\n",
    "\n",
    "#print(number)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
